<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sourav Chakraborty</title>

  <meta name="author" content="Sourav Chakraborty">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/cu-logo.png">
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@500&display=swap" rel="stylesheet">
  <style>
    p {
      text-align: justify;
    }
  </style>
  <script type="text/javascript"
    async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>

  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=PT+Sans&display=swap" rel="stylesheet">
 <!-- manual edit for gentium -->
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Gentium+Basic:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">


<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sourav Chakraborty</name><br>
                <span style="font-size: small; color: rgb(222, 144, 99);">Ph.D. Candidate · Theoretical Machine Learning · University of Colorado</span>
                <p style="text-align: center; font-style: italic; color: #555; font-size: small;">
                  "All models are wrong, but some are useful." – George Box
                </p>

                <p style="text-align: center; font-size: small; color: gray; margin-top: 5px;">
                  [Name pronounced either as <span style="color:#03c295"><em>Saw-rv</em></span> or <span style="color:#03c295"><em>Show-oo-rob</em></span> (Bengali)]
                </p>
              </p>
              
              <!-- <p>
                I am a Ph.D. candidate at the <a href="https://www.colorado.edu/">University of Colorado Boulder</a>, working as a Graduate Research Assistant at the <a href="https://www.colorado.edu/cs/">Department of Computer Science</a>. I am advised by <a href="https://spot.colorado.edu/~lich1539/">Prof. Lijun Chen</a>.
              </p>
              <p>
                My research focuses on the mathematical foundations of sequential decision-making under uncertainty, particularly, Multi-Armed Bandit models and Reinforcement Learning.
              </p>

              <p>
                Outside of research, teaching and mentorship are a crucial part of my academic work. I have served as a Teaching Assistant and the Instructor of Record for multiple semesters. I also served as the CS Department Lead Teaching Assistant from 2022 to 2025, where I coordinated instructional strategies and mentored the graduate teaching cohort across the department.

Prior to my doctoral studies, I completed my Master’s in Computer Science at CU Boulder. Before moving to the U.S., I spent time in the industry as a Software Engineer at Flipkart in Bangalore, India, designing scalable search pipelines and data recovery platforms. I earned my Bachelor's degree from BIT Mesra.
              </p> -->
<!--               
              <p>
                Prior to my Ph.D., I completed a Master’s in Computer Science at the University of Colorado Boulder. I earned my bachelor's degree from the <a href="https://www.bitmesra.ac.in/">Birla Institute of Technology, Mesra</a> in Ranchi, India, and worked as a software engineer at <a href="https://www.linkedin.com/company/flipkart/">Flipkart</a> in Bangalore before moving to the United States.
              </p>
              
              <p>
                Beyond research, I find myself drawn to <a href="https://letterboxd.com/souravchk/">cinema</a>, <a href="https://www.goodreads.com/user/show/50985172-sourav-chakraborty">literature</a>, and music. 
                Cricket has been a constant since childhood: I played for a local club at school and later for the Flipkart team, and now follow the game closely as a spectator.
              </p> --> 

              <p>
                I am a <strong>Ph.D. candidate</strong> at the <a href="https://www.colorado.edu/">University of Colorado Boulder</a>, working as a Graduate Research Assistant in the <a href="https://www.colorado.edu/cs/">Department of Computer Science</a>. I am advised by <a href="https://spot.colorado.edu/~lich1539/">Prof. Lijun Chen</a>. 
              </p>
              
              <p>
                My research focuses on the mathematical foundations of sequential decision-making under uncertainty, with a primary emphasis on <strong>Multi-Agent Reinforcement Learning (MARL)</strong> and <strong>Multi-Armed Bandits</strong>. I investigate how structural, physical, and strategic constraints shape the limits of learnability, particularly in decentralized coordination, continuous action spaces, and evolving networked structures.
              </p>

              
              <p>
                Prior to my Ph.D., I earned my Master’s in Computer Science at the University of Colorado Boulder and my bachelor's degree from the <a href="https://www.bitmesra.ac.in/">Birla Institute of Technology, Mesra</a>. Before moving to the U.S., I worked as a Software Engineer at <a href="https://www.linkedin.com/company/flipkart/">Flipkart</a> in Bangalore, designing scalable search pipelines and centralized data recovery platforms.              </p>
              <p>
                Beyond research, I find myself drawn to <a href="https://letterboxd.com/souravchk/">cinema</a>, <a href="https://www.goodreads.com/user/show/50985172-sourav-chakraborty">literature</a>, and music. Cricket has been a constant since childhood: I played for a local club at school, later for the Flipkart corporate team, and now follow the game closely as a spectator.
              </p>

              <p style="text-align: center; font-style: italic; color: #dc1313;">
                <strong>I am currently on the job market for Fall 2026.</strong>
              </p>
              
              <p>
                <span style="color: rgb(214, 7, 117); font-size: inherit;"><strong style="font-size: inherit;">Fun Fact.</strong></span> My <a href="https://en.wikipedia.org/wiki/Erd%C5%91s_number" style="font-size: inherit;">Erdős Number</a> is 4 and <a href="https://www.csauthors.net/sourav-chakraborty-009/" style="font-size: inherit;">Dijkstra Number</a> is 5.
              </p>

              <!-- <p>
                <span style="color: rgb(186, 69, 10)"><strong>Fun Fact.</strong></span> My <a href="https://en.wikipedia.org/wiki/Erd%C5%91s_number">Erdős Number</a> is 4 and <a href="https://www.csauthors.net/sourav-chakraborty-009/">Djikstra Number</a> is 5.
              </p> -->
              <br>
              <p style="text-align:center">
                <a href="mailto:sourav.chakraborty@colorado.edu">Email</a> &nbsp;&bull;&nbsp;
                <a href="https://www.linkedin.com/in/souravchk/">LinkedIn</a> &nbsp;&bull;&nbsp;
                <a href="">CV</a> &nbsp;&bull;&nbsp;
                <a href="https://scholar.google.com/citations?hl=en&user=19m6XE4AAAAJ&view_op=list_works&gmla=AGd7smHpS_EnoiQAq2ZKg0HR-LbWuXLjTYG_sAkcVx5h64AYMayt6U69y1LvGuhMHYBrj_l-Fm_KIMJX0olMTkBC">Google Scholar</a> <br>
                <span style="display:inline-block; margin-top:5px;">
                  <a href="https://letterboxd.com/souravchk/">Letterboxd</a> &nbsp;&bull;&nbsp;
                  <a href="https://www.goodreads.com/user/show/50985172-sourav-chakraborty">Goodreads</a>
                </span>
              </p>
              
              </p>
            </td>
            <td style="padding:0.5%; width:75%; max-width:75%;">
              <a href="images/ouray-full.jpg" target="_blank">
                <img 
                  style="width:100%; max-width:100%; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); margin-top: 10px;" 
                  alt="profile photo" 
                  src="images/ouray-cut.jpg" 
                  class="hoverZoomLink">
              </a>
              <p style="text-align: center; font-style: italic; font-size: x-small; color: #666; margin-top: 1px;">
                Taken in Ouray, Colorado, <br> known as "The Switzerland of America".
              </p>
            </td>
              <!-- <a href="images/ouray-brown-full.jpg" target="_blank">
                <img 
                  style="width:100%; max-width:100%; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); margin-top: 95px;" 
                  alt="profile photo" 
                  src="images/ouray-brown.jpg" 
                  class="hoverZoomLink">
              </a>
              <p style="text-align: center; font-style: italic; font-size: x-small; color: #666; margin-top: 1px;">
                Taken in Ouray, Colorado, <br> known as "The Switzerland of America".
              </p>
            </td> -->
            
            
            
            
            
          </tr>

        

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <heading>Updates & News</heading>
              <div style="max-height: 280px; overflow-y: auto; padding-right: 10px;">
              <ul>
                <li><strong>2026-02</strong>: <span style="color: green">Defended</span> <strong>PhD Proposal</strong> (Comprehensive) Exam!
                <li><strong>2026-01</strong>: Paper <span style="color:green">accepted</span> at <strong> AISTATS 2026!</strong> Tangier, Morocco.</li>
                <li><strong>2026-01</strong>: <strong>Two</strong> papers <span style="color:green">accepted</span> at <strong> L4DC 2026!</strong>, Los Angeles, CA.</li>
                <li><strong>2025-09</strong>: Paper <span style="color:green">accepted</span> at <strong> NeurIPS 2025 workshop ARLET!</strong>, San Diego, CA.</li>
                <li><strong>2025-07</strong>: <a href="https://arxiv.org/pdf/2508.19466">Paper</a> <span style="color:green">accepted</span> at <strong>IEEE CDC 2025!</strong>, Rio De Janeiro, Brazil.</li>
                <li><strong>2024-12</strong>: <span style="color: green">Cleared</span> the Computer Science <strong>PhD Prelims</strong> (Area) Exam!</li>
                <li><strong>2024-03</strong>: Continuing as a <a href="https://www.colorado.edu/cs/">CS</a> <strong>Department Lead TA</strong> for the AY 2024-25.</li>
                <li><strong>2024-01</strong>: <a href="https://arxiv.org/pdf/2403.10819">My first paper</a> got <span style="color:green">accepted</span> at <strong> IEEE ACC 2024!</strong>, Toronto, Canada.</li>
                <li><strong>2023-08</strong>: Guest lectured for Fall 2023 Advanced ML course on Bandit models.</li>
		<li><strong>2023-03</strong>: <span style="color: green">Elected</span> as the student representive for the <a href="https://bouldercsgrads.org/officers">CS Graduate Committee</a>.</li>
		<li><strong>2023-03</strong>: Re-appointed as a <a href="https://www.colorado.edu/cs/">CS</a> <strong>Department Lead TA</strong> for the AY 2023-24.</li>
                <li><strong>2022-08</strong>: <strong>Started my PhD</strong> journey at the University of Colorado Boulder in CS!</li>
                <li><strong>2022-05</strong>: <span style="color: green">Graduated</span> with <strong>Master of Science (MS)</strong> in Computer Science!
                <li><strong>2022-04</strong>: <span style="color:green">Successfully defended</span> <strong>Master's thesis!</strong> (<a href="https://www.proquest.com/pqdtglobal/docview/2681066075/AD79799B18734CCAPQ/1?accountid=14503">link</a>/
                  <a href="https://drive.google.com/file/d/1wh9OgLBMrK8iCFypy_4BC1VmjSxOK93M/view?usp=sharing">slides</a>)</li>
                <li><strong>2022-02</strong>: Got offer for Ph.D from <a href="https://www.colorado.edu/cs/">CS @ Colorado</a> for Fall 2022!</li>
                <li><strong>2019-08</strong>: Started Master of Science in Computer Science at <a href="https://www.colorado.edu/">Colorado!</a></li>
                <li><strong>2016-12</strong>: Joined <a href="https://www.linkedin.com/company/flipkart/">Flipkart</a> as a Software Engineer in Bangalore, India. </li>
			        <li><strong>2016-06</strong>: Bachelor's in Engineering (B.E.) completed from <a href="https://www.bitmesra.ac.in/">BIT Mesra</a>.</li>
              </ul>
              </div>
            </td>
          </tr>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <heading>Awards & Honors</heading>
             
              <ul class="news">
                <!-- <li><strong>2025-08</strong>: Recepient of the  departmental <strong><span style="color: darkmagenta;">Research Assistant Fellowship</span></strong> for AY 2025-26.</li> -->
                <li><strong>2026-01</strong>: Recepient of the  <strong><span style="color: darkmagenta;">Conference Travel Award </span></strong> for CDC in Rio de Janeiro, Brazil 2025.</li>
                <li><strong>2025-11</strong>: Recepient of the  <strong><span style="color: darkmagenta;">Graduate Research Assistant Fellowship</span></strong> for Spring 2026.</li>
                <li><strong>2025-04</strong>: Recepient of the  <strong><span style="color: darkmagenta;">Outstanding Teaching Assistant Award</span></strong> from the CS department.</li>
                <li><strong>2025-04</strong>: Recepient of the  <strong><span style="color: darkmagenta;">Outstanding Service Award</span></strong> from the CS department.</li>
		            <li><strong>2024-04</strong>: Recepient of the  <strong><span style="color: darkmagenta;">Outstanding Research Paper Award</span></strong> from the CS department.</li>
                <li><strong>2024-04</strong>: Recepient of the  <strong><span style="color: darkmagenta;">Full Conference Travel Fellowship </span></strong> for ACC in Toronto, Canada 2024.</li>
                <li><strong>2024-04</strong>: Recepient of the  <strong>CU research Expo</strong> research <strong><span style="color: darkmagenta;">poster award</span></strong> for the annual year 2023-24.</li>
                <li><strong>2024-03</strong>: Recepient of the  <strong><span style="color: darkmagenta;">Publication Recognition Award</span></strong> for the annual year 2023-24.</li>
                <li><strong>2022-09</strong>: Recepient of the  <strong><span style="color: darkmagenta;">Early Career Development Fellowship </span></strong> from the CS department.</li>
                <li style="padding-left:7ch; text-indent:-7ch;"><strong>2022-05</strong>: Recepient of the  <strong><span style="color: darkmagenta;">Lloyd Botway Award for Outstanding Master's student </span></strong> for "recognizing <br> excellence in academics, teaching, research, and service <strong>among the graduating cohort.</strong>"</li>
                <li><strong>2022-04</strong>: Recepient of the  <strong>CU research Expo</strong> research <strong><span style="color: darkmagenta;">poster award</span></strong> for the annual year 2021-22.</li>
                <li><strong>2022-04</strong>: Selected as a <strong><span style="color: darkmagenta;">Lead Teaching Assistant</span></strong> (department lead) for <a href="https://www.colorado.edu/cs/">CS @ CU</a> for the annual year.</li>
              </ul>
            </td>
          </tr>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Research</heading>
                <p>
                  I develop the mathematical foundations of sequential decision-making to establish how structural, physical, and strategic constraints shape the limits of learnability in uncertain and stochastic environments. 
                  My overarching research agenda focuses on three core areas: 
                  <strong>(i) Scalable Multi-Agent Reinforcement Learning</strong>, where I develop theoretical frameworks to overcome the curse of dimensionality by exploiting policy-dependent locality; 
                  <strong>(ii) Graph-Constrained & Dynamic Bandits</strong>, characterizing the limits of online learning when an agent's actions are restricted by evolving network topologies; 
                  and <strong>(iii) Continuous & Incentivized Learning</strong>, designing sequential decision-making algorithms for Lipschitz-structured action spaces and environments with biased feedback.
                </p>
            </tbody>
          </table>
          

       
        
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>

            
            <tr onmouseout="aistats_stop()" onmouseover="aistats_start()">
              <td style="padding:0px;width:25%;vertical-align:top; text-align:center; padding-left:12px;">
                <div class="one">
                  <div class="two" id='aistats_image'>
                    <img src='images/aistats-logo.webp' width="176"></div>
                  <img src='images/aistats-logo.webp' width="176">
                </div>
                <script type="text/javascript">
                  function aistats_start() {
                    document.getElementById('aistats_image').style.opacity = "1";
                  }

                  function aistats_stop() {
                    document.getElementById('aistats_image').style.opacity = "0";
                  }
                  aistats_start()
                </script>
              </td>
              <td style="padding:14px 20px;width:75%;vertical-align:top">
                <a href="">
                  <papertitle> Multi-Agent Lipschitz Bandits.</papertitle>
                </a>
                <br>
                <strong>Sourav Chakraborty*</strong>, Amit Kiran Rege*, Claire Monteleoni, Lijun Chen  
                <br>
                <em><strong><span style="color: green">Accepted</span> at International Conference of Artificial Intelligence and Statistics (AISTATS) 2026</strong> in Tangier, Morocco.</em>
                <br>
                <a href="https://arxiv.org/abs/AISTATS_2026_ARXIV_ID">arXiv (preprint)</a>
                <div style="height:4px;"></div>
                <div style="font-size: small;text-align: justify; margin-top: 2px; margin-bottom:0;">
                  <strong>Abstract (short):</strong> We introduce a communication-free, modular protocol for decentralized multi-player bandits over continuous, Lipschitz-structured action spaces. Our approach decouples agent coordination from exploration, achieving near-optimal regret without horizon-dependent coordination costs.
                </div>
                  
              </td>
            </tr>

            <tr onmouseout="l4dc1_stop()" onmouseover="l4dc1_start()">
              <td style="padding:0px;width:25%;vertical-align:top; text-align:right;">
                <div class="one">
                  <div class="two" id='l4dc1_image'>
                    <img src='images/l4dc2026.jpg' width="90"></div>
                  <img src='images/l4dc2026.jpg' width="90">
                </div>
                <script type="text/javascript">
                  function l4dc1_start() {
                    document.getElementById('l4dc1_image').style.opacity = "1";
                  }

                  function l4dc1_stop() {
                    document.getElementById('l4dc1_image').style.opacity = "0";
                  }
                  l4dc1_start()
                </script>
              </td>
              <td style="padding:14px 20px;width:75%;vertical-align:top">
                <a href="">
                  <papertitle> Flickering Multi-Armed Bandits.</papertitle>
                </a>
                <br>
                <strong>Sourav Chakraborty*</strong>, Amit Kiran Rege*, Claire Monteleoni, Lijun Chen  
                <br>
                <em><strong><span style="color: green">Accepted</span> at Learning for Dynamics & Control Conference (L4DC) 2026</strong> in Los Angeles, California, United States. </em> <strong style="color:#f12e0b;">(Selected as an Oral Presentation; ~Top 10%)</strong>
                <br>
                <a href="https://arxiv.org/abs/L4DC_2026_FLICKERING_ARXIV_ID">arXiv (preprint)</a>
                <div style="height:4px;"></div>
                <div style="font-size: small;text-align: justify; margin-top: 2px; margin-bottom:0;">
                  <strong>Abstract (short):</strong> We formalize a novel bandit framework where arm availability is constrained by local moves on evolving random graphs (Erdős–Rényi and Edge-Markovian). We design a two-phase algorithm utilizing lazy random walks to achieve near-optimal, sublinear regret under these non-stationary physical constraints.
                </div>
                  
              </td>
            </tr>

            <tr onmouseout="l4dc2_stop()" onmouseover="l4dc2_start()">
              <td style="padding:0px;width:25%;vertical-align:top; text-align:right;">
                <div class="one">
                  <div class="two" id='l4dc2_image'>
                    <img src='images/l4dc2026.jpg' width="90"></div>
                  <img src='images/l4dc2026.jpg' width="90">
                </div>
                <script type="text/javascript">
                  function l4dc2_start() {
                    document.getElementById('l4dc2_image').style.opacity = "1";
                  }

                  function l4dc2_stop() {
                    document.getElementById('l4dc2_image').style.opacity = "0";
                  }
                  l4dc2_start()
                </script>
              </td>
              <td style="padding:14px 20px;width:75%;vertical-align:top">
                <a href="">
                  <papertitle> A Unified Framework for Locality in Scalable MARL. </papertitle>
                </a>
                <br>
                <strong>Sourav Chakraborty*</strong>, Amit Kiran Rege*, Claire Monteleoni, Lijun Chen  
                <br>
                <em><strong><span style="color: green">Accepted</span> at Learning for Dynamics & Control Conference (L4DC) 2026</strong> in Los Angeles, California, United States. </em>
                <br>
                <a href="https://arxiv.org/abs/L4DC_2026_MARL_ARXIV_ID">arXiv (preprint)</a>
                <div style="height:4px;"></div>
                <div style="font-size: small;text-align: justify; margin-top: 2px; margin-bottom:0;">
                  <strong>Abstract (short):</strong> We establish that locality in decentralized MARL is inherently policy-dependent, introducing a novel spectral condition that decouples environmental coupling from policy smoothness. This framework enables policy improvement that circumvents the curse of dimensionality.
                </div>
                  
              </td>
            </tr>

            <tr onmouseout="arlet_stop()" onmouseover="arlet_start()">
              <td style="padding:0px;width:25%;vertical-align:top;text-align:right;  padding-left:20px;" >
                <div class="one">
                  <div class="two" id='cdc25_image'>
                    <img src='images/neurips_logo.png' width="154"></div>
                  <img src='images/neurips_logo.png' width="154">
                </div>
                <script type="text/javascript">
                  function arlet_start() {
                    document.getElementById('cdc25_image').style.opacity = "1";
                  }
  
                  function arlet_stop() {
                    document.getElementById('cdc25_image').style.opacity = "0";
                  }
                  arlet_start()
                </script>
              </td>
              <td style="padding:14px 20px;width:75%;vertical-align:top">
                <a href="">
                  <papertitle> Bandit Learning on Dynamic Graphs.</papertitle>
                </a>
                <br>
                <strong>Sourav Chakraborty*</strong>, Amit Kiran Rege*, Claire Monteleoni, Lijun Chen  
                <br>
                <em><strong><span style="color: green">Accepted</span> at ARLET Workshop at Neural Information Processing Systems (NeurIPS) 2025</strong> in San Diego, California, United States.</em>
                <br>
                <!-- <a href="">IEEE version </a>&nbsp/ -->
                <a href="">arXiv</a>
                <div style="height:4px;"></div>
                <div style="font-size: small;text-align: justify; margin-top: 2px; margin-bottom:0;">
                  <strong>Abstract (short):</strong> We study online learning where an agent is constrained to local movements on a dynamic graph sequence. 
                  We formalizing sufficient structural conditions for learnability and design near-optimal, exploration policies.
                  <!-- Abstract removed for brevity.
                  We study an online learning setting where an agent's actions are constrained to local movements on a dynamic graph, a setting that captures scenarios such as autonomous reconnaissance. This problem highlights a core challenge in adaptive systems: how to learn effectively with only partial, localized feedback in a non-stationary environment. We propose a set of structural conditions, termed <em>Recurrent Reachability</em> and <em>Temporal Stability</em>, that are sufficient for learnability. Our analysis reveals a foundational <em>anatomy of regret</em>, decomposing it into a statistical learning cost and a physical navigation cost. We introduce a family of local algorithms, progressing from a canonical protocol to a more practical, adaptive variant, and culminating in a reward-aware exploration policy that achieves provably near-optimal regret on any graph sequence satisfying our conditions. We corroborate our theory in a disaster-response simulation.
                  -->
                </div>
                  
              </td>
            </tr>

    

            <tr onmouseout="cdc25_stop()" onmouseover="cdc25_start()">
              <td style="padding:0px;width:25%;vertical-align:top;">
                <div class="one">
                  <div class="two" id='cdc25_image'>
                    <img src='images/cdc25-intro-fig.png' width="220"></div>
                  <img src='images/cdc25-intro-fig.png' width="220">
                </div>
                <script type="text/javascript">
                  function cdc25_start() {
                    document.getElementById('cdc25_image').style.opacity = "1";
                  }
  
                  function cdc25_stop() {
                    document.getElementById('cdc25_image').style.opacity = "0";
                  }
                  cdc25_stop()
                </script>
              </td>
              <td style="padding:14px 20px;width:75%;vertical-align:top">
                <a href="">
                  <papertitle> Incentivized Lipschitz Bandits.</papertitle>
                </a>
                <br>
                <strong>Sourav Chakraborty*</strong>, Amit Kiran Rege*, Claire Monteleoni, Lijun Chen  
                <br>
                <em><strong><span style="color: green">Accepted</span> at IEEE Conference on Decision and Control (CDC) 2025</strong> in Rio de Janeiro, Brazil.</em>
                <br>
                <a href="https://ieeexplore.ieee.org/document/11312562">IEEE</a>&nbsp/
                <a href="https://arxiv.org/pdf/2508.19466">arXiv</a>
                <div style="height:4px;"></div>
                <div style="font-size: small;text-align: justify; margin-top: 2px; margin-bottom:0;">
                  <!-- Abstract removed for brevity.
                  We study incentivized exploration in bandit settings with infinitely many arms over continuous metric spaces. A principal offers compensation to myopic agents to encourage exploration, but must contend with reward drift due to biased feedback. 

                  We develop discretization-based algorithms that achieve both sublinear regret and sublinear compensation, with guarantees of \( \widetilde{O}(T^{(d+1/d+2)}) \) where \( d \) is the covering dimension. We extend our approach to contextual bandits and validate it through simulations.
                  -->
                  <strong>Abstract (short):</strong> We develop incentivized exploration schemes in continuous metric spaces where the system compensates myopic agents to explore, despite receiving biased feedback. We develop near-optimal uniform discretization-based algorithms.
                </div>
                  
              </td>
            </tr>

          <tr onmouseout="acc24_stop()" onmouseover="acc24_start()">
            <td style="padding:10px;width:25%;vertical-align:top; padding-left:20px">
              <div class="one">
                <div class="two" id='acc24_image'>
                  <img src='images/acc24-2.png' width="180"></div>
                <img src='images/acc24-2.png' width="180">
              </div>
              <script type="text/javascript">
                function acc24_start() {
                  document.getElementById('acc24_image').style.opacity = "1";
                }

                function acc24_stop() {
                  document.getElementById('acc24_image').style.opacity = "0";
                }
                acc24_stop()
              </script>
            </td>
            <td style="padding:14px 20px;width:75%;vertical-align:top">
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10644966">
                <papertitle> Incentivized Exploration in Non-stationary Stochastic Bandits.</papertitle>
              </a>
              <br>
              <strong>Sourav Chakraborty</strong> and Lijun Chen.
              <br>
              <em><strong><span style="color: green">Accepted</span> at IEEE American Control Conference (ACC) 2024</strong> in Toronto, Canada.</em>
              <br>
              <em><strong>Master's Thesis</strong>, <span style="font-size: small;">Committee: <a href="https://spot.colorado.edu/~lich1539/">Lijun Chen</a>,
                <a href="https://home.cs.colorado.edu/~raf/">Raf Frongillo</a>, <a href="https://www.bowaggoner.com/">Bo Waggoner.</a></span></em> 
              <br>
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10644966">IEEE version</a>&nbsp/
              <a href="https://arxiv.org/pdf/2403.10819">arXiv</a>&nbsp/
              <a href="https://www.proquest.com/pqdtglobal/docview/2681066075/AD79799B18734CCAPQ/1?accountid=14503">thesis</a>
              <div style="height:4px;"></div>
              <div style="font-size: small;text-align: justify; margin-top: 2px; margin-bottom:0;">
                <!-- Abstract removed for brevity.
                We study incentivized exploration in non-stationary bandit settings, where agents receive compensation to explore beyond their greedy choices, but report biased feedback. 

                We propose algorithms for both abruptly-changing and continuously-drifting environments, and show they achieve sublinear regret and compensation, even under biased rewards, thus enabling effective exploration over time.
                -->
                <strong>Abstract (short):</strong> We address the challenge of incentivizing myopic agents to explore in both abruptly-changing and continuously-drifting bandit environments with drifted feedback and propose near-optimal algorithms.
              </div>
             <!-- <p>We explore incentivized exploration in the multiarmed bandit (MAB) problem with changing reward distributions and biased feedback. Our algorithms address abruptly and continuously changing environments, achieving sublinear regret and compensation, effectively incentivizing exploration despite challenges. -->
               </p>
              </td>
          </tr>
          </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <!-- <td style="padding:2.5%;width:100%;vertical-align:middle">
              <heading>Essays</heading>
              <ul>
                <li>[May 2018] - Exploring Probabilistic Data Structures: Bloom Filters <a href="https://opensourceforu.com/2018/05/exploring-probabilistic-data-structures-bloom-filters/">[link]</a></li>
              </ul>
            </td> -->
          </tr>
          </tbody>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Work Experience</heading>
              <p style="margin-bottom: 4px;">
                I worked on production systems at Flipkart across storage/reliability infrastructure and search relevance, with a focus on product discovery, ranking, and data reliability.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:4px 20px 20px 20px;width:10%;vertical-align:middle;text-align: justify"><img width="130",height="130", src="images/fk-logo.png"></td>
            <td style="padding:4px 20px 20px 20px;" width="75%" valign="center">
              <p style="margin-top: 0; margin-bottom: 6px;">
                <strong>Software Engineer</strong> at <strong>Flipkart</strong>
              </p>
              <!-- Original text retained for future reuse:
              <ul>
                <li>Built an end-to-end <strong>Searches and Shopping Ideas</strong> pipeline in Java Cascading that suggests contextually relevant queries, broadening what shoppers can discover as they type.  </li>
                <li>Designed <strong>learning-driven ranking signals</strong> that improved how relevant results surface across the search experience.</li>
                <li>Built a <strong>pluggable backup platform</strong> with MySQL drivers that matured into BRaaS (Backup Recovery as a Service), the centralized service safeguarding and restoring data for every Flipkart application.</li>
              </ul>
              -->
              <ul>
                <li>Built an end-to-end <strong>query suggestion pipeline</strong> (related search) for search and shopping intents, improving how users discover relevant products while typing.</li>
                <li>Developed and integrated <strong>ranking signals</strong> to improve retrieval quality and relevance ordering in the search experience.</li>
                <li>Built a <strong>pluggable backup platform</strong> (MySQL drivers) that evolved into BRaaS, a centralized backup/recovery service used across multiple Flipkart applications.</li>
                <li>Collaborated across infrastructure and product-search teams on cross-functional engineering efforts spanning discovery quality and system reliability.</li>
            </ul>            
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
              <p style="margin-bottom: 4px;">
                My teaching contributions span undergraduate computer science instruction and department-level instructional support, including course operations, student-facing instruction, assessment, staff training, and mentorship.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:4px 20px 20px 20px;width:10%;vertical-align:middle;text-align: justify"><img width="100",height="100", src="images/cu-icon.png"></td>
            <td style="padding:4px 20px 20px 20px;" width="75%" valign="center">
              <ul>
                <li><strong>Instructor of Record</strong>
                  <ul style="margin-top: 2px; margin-bottom: 5px;">
                    <li>CSCI 1200: Introduction to Computational Thinking (Fall 2021)</li>
                    <li>CSCI 3022: Introduction to Data Science with Probability &amp; Statistics (Summer 2020)</li>
                    <li>Primary instructor responsible for end-to-end course delivery (lecture planning, instruction, assessments, and final grading), including coordination of instructional staff; enrollments were <strong>~200</strong> and <strong>~50</strong>, respectively.</li>
                  </ul>
                </li>
                <li><strong>CS Department Lead Teaching Assistant</strong> (2022 - 2025)
                  <ul style="margin-top: 2px; margin-bottom: 5px;">
                    <li>Selected by the department via teaching-performance review and interviews to support department-wide instructional quality.</li>
                    <li>Helped conduct <strong>TA hiring</strong> interviews and ran <strong>annual onboarding/training</strong> for new TAs, graders, and instructional staff.</li>
                    <li>Organized <strong>recurring workshops</strong>, mentored graduate TAs, and served as a liaison to communicate TA concerns to department leadership.</li>
                  </ul>
                </li>
                <li><strong>Graduate Teaching Assistant</strong> (2020 - 2025)
                  <ul style="margin-top: 2px; margin-bottom: 5px;">
                    <li>Algorithms (CSCI 3104), Data Structures (CSCI 2270/2275), and Starting Computing (CSCI 1300), across <strong>10+ semesters</strong>.</li>
                    <li>Responsibilities included weekly recitations, office hours, quizzes/lab facilitation, and assignment/exam grading.</li>
                  </ul>
                </li>
            </ul>
            </td>
          </tr>
        </tbody></table>
  
  



        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Selected Personal Projects</heading>
            <p style="font-size:small">*Alphabetically</p>
          </td>
        </tr>
      </tbody></table>


      
      

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>

        <tr onmouseout="dmu_stop()" onmouseover="dmu_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='dmu_image'>
                <img src='images/dmu-results.png' width="200"></div>
              <img src='images/gridworld_mdp.png' width="150">
            </div>
            <script type="text/javascript">
              function dmu_start() {
                document.getElementById('dmu_image').style.opacity = "1";
              }

              function dmu_stop() {
                document.getElementById('dmu_image').style.opacity = "0";
              }
              dmu_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/tuhina2313/DMU_Project">
              <papertitle> Inverse Reinforcement Learning via Maximum Entropy Formulation.</papertitle>
            </a>
            <br>
            Tuhina Tripathi, Alexa Reed, <strong>Sourav Chakraborty</strong> 
            <br>
            <em>April </em>, 2022  
            <br>
            <a href="files/DMU_Project_Report.pdf">report</a> &nbsp/&nbsp
            <a href="https://github.com/tuhina2313/DMU_Project">code</a>&nbsp/&nbsp
            <a href="https://drive.google.com/file/d/1bngSjiP8bu8pldSw_C_z4oDS2hn0NkqM/view?usp=sharing">demo</a>&nbsp/&nbsp
            <a href="https://github.com/souravchk25/dmu-interface/tree/master/">interface-code</a>
            <p></p>
            <p>
              Final project for ASEN 5519: Decision Making Under Uncertainty. This project explores the use of Inverse Reinforcement Learning, via Maximum Entropy Formulation, in a Markov Decision Process. The concepts explored in this project were  demonstrated using a grid world environment. 
              </p> 
            </td>
        </tr>

        <tr onmouseout="imab_stop()" onmouseover="imab_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='imab_image'>
                <img src='images/imab_after.png' width="160"></div>
              <img src='images/imab_before.png' width="160">
            </div>
            <script type="text/javascript">
              function imab_start() {
                document.getElementById('imab_image').style.opacity = "1";
              }

              function imab_stop() {
                document.getElementById('imab_image').style.opacity = "0";
              }
              imab_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/souravchk25/multiarmed-bandits-reward-drift">
              <papertitle> Incentivized Exploration for Multi-Armed Bandits under Reward Drift.</papertitle>
            </a>
            <br>
            <strong>Sourav Chakraborty</strong> 
            <br>
            <em>September</em>, 2020  
            <br>
            <a href="https://arxiv.org/abs/1911.05142">original paper</a> &nbsp/&nbsp
            <a href="https://github.com/souravchk25/multiarmed-bandits-reward-drift">code</a>
            <p></p>
            <p>
              Just playing around with the <a href="https://arxiv.org/abs/1911.05142">paper by Liu & Wang et al</a>on Incentivized Exploration for Multi-Armed Bandits under Reward Drift
              where the players receive compensation for exploring arms other than the greedy choice and may provide biased feedback on reward drift.
             </p> 
            </td>
        </tr> 

        <tr onmouseout="we_stop()" onmouseover="we_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='we_image'>
                <img src='images/swe_after.PNG' width="160"></div>
              <img src='images/swe_before.png' width="160">
            </div>
            <script type="text/javascript">
              function we_start() {
                document.getElementById('we_image').style.opacity = "1";
              }

              function we_stop() {
                document.getElementById('we_image').style.opacity = "0";
              }
              we_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://drive.google.com/file/d/1uWGw--LCC-tMqtquTySHe9aCjUHyccRK/view">
              <papertitle> Contextual vectorized representation of words: Soam word embeddings</papertitle>
            </a>
            <br>
            *<a href="https://www.amitbaranroy.com/">Amit Baran Roy</a>, <strong>Sourav Chakraborty</strong> 
            <br>
            <em>May</em>, 2020  
            <br>
            <a href="https://drive.google.com/file/d/1uWGw--LCC-tMqtquTySHe9aCjUHyccRK/view">report</a> &nbsp/&nbsp
            <a href="https://github.com/AmitProspeed/SOAM-Word-Embeddings">code</a>
            <p></p>
            <p>A word embedding model implementation based on the popular skipgram architecture. It involves alterations of the scoring algorithm to give more weightage to the context words that are closer to the target word in a skipgram sliding window.</p>
          </td>
        </tr> 


        <tr onmouseout="agt_stop()" onmouseover="agt_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='agt_image'>
                <img src='images/agt_after.png' width="160"></div>
              <img src='images/agt_before.png' width="160">
            </div>
            <script type="text/javascript">
              function agt_start() {
                document.getElementById('agt_image').style.opacity = "1";
              }

              function agt_stop() {
                document.getElementById('agt_image').style.opacity = "0";
              }
              agt_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://github.com/souravchk25/alg-game-theory-project/blob/master/AGTFinalProjectReport_Sourav_Naga.pdf">
              <papertitle>Solving Games using the combination of Q-learning and Regret Matching Methods</papertitle>
            </a>
            <br>
            <strong>Sourav Chakraborty</strong>, <a href="https://www.linkedin.com/in/nagarajan-shanmuganathan">Nagarajan Shanmuganathan</a> 
            <br>
            <em>May</em>, 2020  
            <br>
            <a href="https://github.com/souravchk25/alg-game-theory-project/blob/master/AGTFinalProjectReport_Sourav_Naga.pdf">report</a> &nbsp/&nbsp
            <a href="https://github.com/souravchk25/alg-game-theory-project">code</a> 
            <p></p>
            <p>It is known well that Counterfactual regret minimization
              (CFR) has been used in games which have both terminal states and perfect recall to minimize regret. This project aims to relax those constraints
              and use a local no-regret algorithm (LONR) by <a href="https://arxiv.org/pdf/1910.03094.pdf">Kash et al</a>, which internally uses a Q-learning like update rule to games which do not have terminal states or
              perfect recall.</p>
          </td>
        </tr> 

        <tr onmouseout="thresh_stop()" onmouseover="thresh_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='thresh_image'>
                <img src='images/onw_after.PNG' width="160"></div>
              <img src='images/onw_before.PNG' width="160">
            </div>
            <script type="text/javascript">
              function thresh_start() {
                document.getElementById('thresh_image').style.opacity = "1";
              }

              function thresh_stop() {
                document.getElementById('thresh_image').style.opacity = "0";
              }
              thresh_stop()
            </script>
          </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
            <a href="https://drive.google.com/file/d/1euDcbe5lZ99nM89ukua4Pgpr2IvIAizB/view">
              <papertitle>Occupancy Network based 3D Image Reconstruction using Single-Depth View</papertitle>
            </a>
            <br>
            *<a href="https://www.amitbaranroy.com/">Amit Baran Roy</a>, <a href="https://www.linkedin.com/in/aparajitasingh10/">Aparajita Singh</a>, <strong>Sourav Chakraborty</strong>, <a href="https://www.linkedin.com/in/tanmai-gajula">Tanmai Gajula</a> 
            <br>
            <em>Feb-April</em>, 2020
            <br>
            <a href="https://drive.google.com/file/d/1euDcbe5lZ99nM89ukua4Pgpr2IvIAizB/view">report</a> &nbsp/&nbsp
            <a href="https://github.com/AmitProspeed/csci5922project">code</a>
            <br>
            <p></p>
            <p>
            The complete 3D geometry of an object from a single 2.5D depth view was acquired by using deep learning techniques such as generative adversarial networks and 3D convolution neural networks. The resolution of the final 3D voxelized output was improved by transforming the voxel representation into another representation called occupancy networks.
            </p>
          </td>
        </tr>
        </tbody></table> -->

	<p style="text-align:center;font-size:x-small;">
            Last updated: Feb 2026 <br> Thanks <a href="https://jonbarron.info/" style="font-size:x-small">Jon Barron!</a>
        </p>
	<div style="text-align: center; margin-top: 30px;">
  		<div style="transform: scale(1.0); transform-origin: top center;">
		     <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=210&t=n&d=bNSuFvzPxUteENuG2yIWqZnlr1-7hFjVir4LoDc1i94&co=bbdef7&cmo=3acc3a&cmn=ff5353&ct=020000'></script>
		</div>
	</div>
       
</body>

</html>
